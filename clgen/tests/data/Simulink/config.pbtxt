# A tiny corpus of OpenCL kernels and a correspondingly small model.
# It should take around 30 minutes to train on a reasonably powerful GPU,
# and maybe around an hour on a CPU.
# File: //deeplearning/deepsmith/proto/clgen.proto
# Proto: clgen.Instance
working_dir: "/Users/sohilshrestha/Downloads/experiments"
pretrained_model:"/Users/sohilshrestha/Desktop/experiments100Epoch64Batch64Seqlength128Units/model/f735fce1969c4ce1c80df2891c8aeb15e7aed10e"
sampler {
  #start_text: "Model {"
  start_text: "Model {\nName \"sampleModel5673\"\n System {\nName \"sampleModel5673\"\nSIDHighWatermark \"17\"\nBlock {"
  #start_text:"Model {\nName \"sampleModel6340\"\nSystem {\nName \"sampleModel6340\"\nLocation [103, 94, 897, 607]\nOpen on\nPortBlocksUseCompactNotation off\nModelBrowserVisibility off\nModelBrowserWidth 200\nScreenColor \"white\"\nPaperOrientation \"landscape\"\nPaperPositionMode \"auto\"\nPaperType \"usletter\"\nPaperUnits \"inches\"\nTiledPaperMargins [0.500000, 0.500000, 0.500000, 0.500000]\nTiledPageScale 1\nShowPageBoundaries off\nZoomFactor \"100\"\nReportName \"simulink-default.rpt\"\nSIDHighWatermark \"15\"\nBlock {"
  batch_size: 1000
  temperature_micros: 800000  # = 0.8 real value
  termination_criteria {
    symtok {
      depth_increase_token: "{"
      depth_decrease_token: "}"
    }
  }
  termination_criteria {
    maxlen {
      maximum_tokens_in_sample: 2500
    }
  }
}
